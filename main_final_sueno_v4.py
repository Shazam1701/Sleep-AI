import os
import re
from io import BytesIO

import streamlit as st
import numpy as np
import pandas as pd
from dotenv import load_dotenv
from openai import OpenAI
from tensorflow.keras.models import load_model
import joblib

from prompts_sueno import stronger_prompt_sueno

# ============================================
# CONFIGURACI√ìN INICIAL (API + MODELO)
# Carga claves de OpenAI, 
# inicializa modelos Whisper / GPT-4o y carga }
# el modelo ANN, scaler y label encoder.
# ============================================

load_dotenv(override=True)
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

if not OPENAI_API_KEY:
    raise ValueError("No se encontr√≥ la variable de entorno OPENAI_API_KEY. Verifica tu archivo .env.")

client_openai = OpenAI(api_key=OPENAI_API_KEY)

# Modelos OpenAI
MODEL_CHAT = "gpt-4o-mini"        # Chat principal
MODEL_TRANSCRIBE = "whisper-1"    # Voz ‚Üí Texto
MODEL_TTS = "gpt-4o-mini-tts"     # Texto ‚Üí Voz


@st.cache_resource
def load_artifacts():
    try:
        # Cargar modelo Keras
        model = load_model("modelos/modelo_sleep.keras")

        # Cargar scaler y encoder
        scaler = joblib.load("modelos/scaler_sleep.pkl")
        label_encoder = joblib.load("modelos/label_encoder_sleep.pkl")

        return model, scaler, label_encoder

    except Exception as e:
        st.error(f"‚ùå Error cargando artefactos: {e}")
        raise e


model_ann, scaler_sleep, label_encoder_sleep = load_artifacts()



# ============================================
# ‚ùì PREGUNTAS DEL FLUJO GUIADO
# ============================================

PREGUNTAS = [
    ("Age", "Para comenzar, ¬øcu√°ntos a√±os tienes? "),
    ("Sleep Duration", "¬øCu√°ntas horas duermes normalmente al d√≠a? (Por ejemplo: 6.5)"),
    ("Stress Level", "En una escala del 0 al 10 donde 0 es nada y 10 mucho, ¬øqu√© tan estresado te encuentras?"),
    ("Physical Activity Level", "¬øCu√°l es el promedio de minutos de actividad f√≠sica en tu d√≠a?"),
]

FEATURE_ORDER = [key for key, _ in PREGUNTAS]


# ============================================
# FUNCIONES AUXILIARES
# ============================================

def extraer_numero(texto, tipo="float"):
    """
    Extrae el primer n√∫mero del texto.
    tipo: "int" o "float"
    """
    if texto is None:
        return None
    coincidencias = re.findall(r"[-+]?\d*\.?\d+", texto.replace(",", "."))
    if not coincidencias:
        return None
    valor = coincidencias[0]
    try:
        if tipo == "int":
            return int(float(valor))
        else:
            return float(valor)
    except ValueError:
        return None


def predecir_calidad_sueno(input_dict):
    """
    Usa el modelo ANN para estimar la calidad del sue√±o.

    Versi√≥n robusta:
    - Respeta FEATURE_ORDER
    - Maneja errores del modelo
    - Devuelve clase y diccionario de probabilidades por etiqueta
    """
    try:
        df = pd.DataFrame([input_dict])[FEATURE_ORDER]
        X = scaler_sleep.transform(df)
        proba = model_ann.predict(X)[0]
        clase_idx = int(np.argmax(proba))
        clase = label_encoder_sleep.inverse_transform([clase_idx])[0]
    except Exception as e:
        print("ERROR en predecir_calidad_sueno:", e)
        return "Unknown", {}

    # Validaci√≥n b√°sica de clase
    clases_validas = list(label_encoder_sleep.classes_)
    if clase not in clases_validas:
        return "Unknown", {}

    proba_dict = {
        label_encoder_sleep.inverse_transform([i])[0]: float(p)
        for i, p in enumerate(proba)
    }

    return clase, proba_dict


def generar_audio(texto):
    """
    Genera audio en MP3 a partir de un texto usando TTS.

    """
    try:
        speech = client_openai.audio.speech.create(
            model=MODEL_TTS,
            voice="alloy",
            input=texto
        )
        audio_bytes = speech.read()
        return audio_bytes
    except Exception as exc:
        st.error(f"No se pudo generar audio: {exc}")
        return None


# ============================================
# REPORTE EJECUTIVO
# ============================================

def generar_reporte_ejecutivo(inputs):
    edad = inputs.get("Age")
    duracion = inputs.get("Sleep Duration")
    estres = inputs.get("Stress Level")
    actividad = inputs.get("Physical Activity Level")

    recomendaciones = []

    # Edad
    if edad is not None:
        if edad < 25:
            recomendaciones.append(
                "A tu edad, el cuerpo requiere entre 7‚Äì9 horas de sue√±o para optimizar aprendizaje y recuperaci√≥n."
            )
        elif edad < 40:
            recomendaciones.append(
                "Entre los 25 y 40 a√±os, mantener un sue√±o regular reduce el riesgo de estr√©s cr√≥nico."
            )
        else:
            recomendaciones.append(
                "A partir de los 40, la calidad del sue√±o tiende a disminuir; prioriza horarios consistentes y buena higiene del sue√±o."
            )

    # Duraci√≥n del sue√±o
    if duracion is not None:
        if duracion < 6:
            recomendaciones.append(
                "Duermes menos de 6 horas. Esto eleva estr√©s, apetito y fatiga. Intenta acercarte a 7‚Äì8 horas de sue√±o real."
            )
        elif duracion < 7:
            recomendaciones.append(
                "Tu sue√±o est√° cerca del nivel √≥ptimo, pero podr√≠as beneficiarte de alcanzar 7‚Äì8 horas constantes."
            )
        else:
            recomendaciones.append(
                "Tu duraci√≥n de sue√±o es adecuada. Mant√©n horarios regulares y evita pantallas antes de dormir."
            )

    # Estr√©s
    if estres is not None:
        if estres >= 7:
            recomendaciones.append(
                "Tu nivel de estr√©s es alto. Considera pausas activas, respiraci√≥n profunda o peque√±os descansos durante el d√≠a."
            )
        elif estres >= 4:
            recomendaciones.append(
                "Tu nivel de estr√©s es moderado. Mantener una rutina estable de sue√±o ayudar√° a evitar que aumente."
            )
        else:
            recomendaciones.append(
                "Tu nivel de estr√©s es bajo, lo cual favorece un sue√±o m√°s profundo y reparador. ¬°Sigue as√≠!"
            )


    # Actividad f√≠sica
    if actividad is not None:
        if actividad < 30:
            recomendaciones.append(
                "Tu actividad f√≠sica es baja. Caminar a paso rapido o trotar al menos 30 minutos al d√≠a puede mejorar significativamente tu calidad de sue√±o."
            )
        elif actividad < 60:
            recomendaciones.append(
                "Tu actividad f√≠sica es moderada. Mantenerla o incrementarla ligeramente puede favorecer a√∫n m√°s tu descanso."
            )
        else:
            recomendaciones.append(
                "Tienes un excelente nivel de actividad f√≠sica, lo que favorece un mejor ciclo sue√±o-vigilia."
            )

    if not recomendaciones:
        recomendaciones.append(
            "No se pudieron generar recomendaciones espec√≠ficas. Verifica que hayas respondido todas las preguntas."
        )

    reporte = "\n".join([f"- {r}" for r in recomendaciones])
    return reporte


# ============================================
# COMANDOS ESPECIALES (CANCELAR / REINICIAR)
# ============================================

def detectar_comando_especial(texto):
    texto = texto.lower().strip()

    comandos_cancelar = [
        "cancelar", "cancel", "stop", "detener", "salir",
        "ya no quiero", "ya no", "no quiero seguir"
    ]

    comandos_reiniciar = [
        "reiniciar", "restart", "volver a empezar", "empezar de nuevo",
        "reset", "desde cero"
    ]

    for c in comandos_cancelar:
        if c in texto:
            return "cancelar"

    for c in comandos_reiniciar:
        if c in texto:
            return "reiniciar"

    return None


def validar_respuesta_numerica(texto, key):
    """
    Valida que el usuario haya escrito un n√∫mero.
    Usa el `key` de la variable para aplicar validaciones b√°sicas de rango.
    Regresa: (valor_float, None) si es v√°lido
             (None, mensaje_error) si no es v√°lido
    """
    if texto is None:
        return None, "Necesito un n√∫mero num√©rico (por ejemplo: 25 o 7.5). ¬øPuedes repetirlo?"

    # Extraer n√∫mero desde el texto (por si dice "tengo 25 a√±os")
    numeros = re.findall(r"[-+]?\d*\.\d+|\d+", texto)

    if not numeros:
        return None, "Necesito un n√∫mero num√©rico (por ejemplo: 25 o 7.5). ¬øPuedes repetirlo?"

    try:
        valor = float(numeros[0])
    except ValueError:
        return None, "Lo que escribiste no parece un n√∫mero v√°lido. Intenta solo con n√∫meros."

    # Validaciones sencillas por variable
    if key == "Age" and not (0 < valor < 120):
        return None, "La edad debe estar entre 1 y 120 a√±os."
    if key == "Sleep Duration" and not (0 < valor <= 24):
        return None, "Las horas de sue√±o deben estar entre 0 y 24."
    if key == "Physical Activity Level" and valor < 0:
        return None, "Los minutos de actividad f√≠sica no pueden ser negativos."
    if key == "Stress Level" and not (0 <= valor <= 10):
        return None, "El nivel de estr√©s debe estar entre 0 y 10."

    return valor, None


# ============================================
# ESTADO INICIAL (SESSION STATE)
# ============================================

if "messages" not in st.session_state:
    st.session_state["messages"] = [
        {
            "role": "assistant",
            "content": (
                "Hola! Soy SleepIA. "
                "Podemos platicar de tus h√°bitos de sue√±o o, si lo prefieres, "
                "puedo hacerte unas preguntas para analizar tu calidad de descanso con un modelo de Inteligencia Artificial."
            ),
        }
    ]

if "modo_analisis" not in st.session_state:
    st.session_state["modo_analisis"] = False

if "inputs_usuario" not in st.session_state:
    st.session_state["inputs_usuario"] = {}

if "indice_pregunta" not in st.session_state:
    st.session_state["indice_pregunta"] = 0


# ============================================
# ONFIGURACI√ìN DE INTERFAZ 
# ============================================

st.set_page_config(page_title="SleepIA", page_icon="üåô üò¥ üí§")
st.title("üí§ Sleep AI")
st.caption("üåô Soy un Chat LLM con un Modelo de Red Neuronal Artificial que clasifica la calidad del sue√±o promedio")

# Contenedor de chat
chat_container = st.container()
with chat_container:
    for msg in st.session_state.messages:
        message_block = st.chat_message(msg["role"])
        message_block.write(msg["content"])
        audio_payload = msg.get("audio")
        if audio_payload:
            message_block.audio(audio_payload, format="audio/mp3")


# ============================================
# SIDEBAR: CONTROLES
# ============================================

with st.sidebar:
    st.subheader("üéß Entrada por voz")
    
    st.markdown("""
    **C√≥mo usar la entrada por voz:**
    1. Presiona el microfono para Grabar audio.
    2. Habla con normalidad (m√°ximo 15‚Äì20 segundos).
    3. Da clic en el boton de Detener (De color rojo)
    4. Da clic en **Enviar audio** para transcribirlo.
    
    > Tip: Puedes responder preguntas del modelo con esta funcion.
    """)
    audio_input = st.audio_input("Graba un mensaje de voz (opcional)")
    send_audio = st.button("Enviar audio", use_container_width=True)

    st.markdown("---")
    st.subheader("üß™ An√°lisis con modelo ANN")
    iniciar_analisis = st.button(
        "Iniciar preguntas del modelo",
        use_container_width=True
    )

# Si el usuario inicia el an√°lisis guiado
if iniciar_analisis:
    if not st.session_state.get("modo_analisis", False):

        # Activar modo an√°lisis
        st.session_state["modo_analisis"] = True
        st.session_state["inputs_usuario"] = {}
        st.session_state["indice_pregunta"] = 0

        # Forzar un mensaje de usuario "fantasma" para refrescar el chat
        st.session_state.messages.append({
            "role": "user",
            "content": " "
        })

        # Mostrar primer mensaje del flujo guiado
        key, pregunta_texto = PREGUNTAS[0]
        texto = (
            "Perfecto üò¥üí°\n\n"
            "Vamos a comenzar tu evaluaci√≥n del sue√±o con IA.\n\n"
            f"{pregunta_texto}"
        )
        st.session_state.messages.append({
            "role": "assistant",
            "content": texto
        })

        st.rerun()

# ============================================
# ENTRADA DE TEXTO / AUDIO
# ============================================

user_prompt = None
user_display = None

# Texto tiene prioridad
if text_prompt := st.chat_input(
    "Escribe c√≥mo dormiste o responde a la pregunta del modelo..."
):
    user_prompt = text_prompt
    user_display = text_prompt

# Si no hay texto, puede venir audio
elif send_audio:
    if audio_input is not None:
        raw_audio = audio_input.getvalue()
        filename = audio_input.name or "voz_usuario.wav"
        audio_file = BytesIO(raw_audio)
        audio_file.name = filename

        with st.spinner("üéß Transcribiendo tu mensaje..."):
            transcription = client_openai.audio.transcriptions.create(
                model=MODEL_TRANSCRIBE,
                file=audio_file,
            )
        user_prompt = transcription.text.strip()
        user_display = f"(Audio) {user_prompt}" if user_prompt else None

        if not user_prompt:
            st.warning("‚ö†Ô∏è No se detect√≥ texto en la grabaci√≥n. Intenta nuevamente.")
    else:
        st.warning("Por favor graba un audio antes de enviarlo.")


# ============================================
# L√ìGICA PRINCIPAL: CHAT + FLUJO ANN (VERSI√ìN B)
# ============================================

def manejar_respuesta_analisis(user_text: str):
    """
    Flujo guiado versi√≥n B (v3) adaptado al dise√±o original.
    - Soporta comandos cancelar/reiniciar
    - Valida n√∫mero por variable
    - Al final llama al ANN, genera reporte y audio
    """

    # =====================================================================
    # SI YA SE ACTIV√ì EL PROCESAMIENTO, GENERAMOS LA PREDICCI√ìN DIRECTO
    # =====================================================================
    if st.session_state.get("procesando_resultado", False):

        inputs = st.session_state["inputs_usuario"].copy()

        with st.spinner("üß† Analizando tu patr√≥n de sue√±o..."):
            clase, proba = predecir_calidad_sueno(inputs)

        recomendaciones_por_clase = {
            "Excelente": [
                "Mant√©n una rutina de sue√±o consistente.",
                "Evita pantallas al menos 45 minutos antes de dormir.",
                "Procura mantener tus buenos h√°bitos de descanso."
            ],
            "Buena": [
                "Intenta dormir entre 7 y 8 horas reales.",
                "Reduce la cafe√≠na despu√©s de las 4 PM.",
                "Establece horarios m√°s constantes para acostarte."
            ],
            "Regular": [
                "Tu descanso podr√≠a mejorar significativamente.",
                "Mejora tu higiene del sue√±o (luz, ruido, temperatura).",
                "Considera t√©cnicas de manejo de estr√©s o hablar con un especialista si persiste."
            ],
        }

        rec = recomendaciones_por_clase.get(clase, ["Mejora tus h√°bitos de sue√±o."])
        while len(rec) < 3:
            rec.append("Contin√∫a mejorando tus h√°bitos para un mejor descanso.")

        reporte = generar_reporte_ejecutivo(inputs)

        txt_final = f"""
üò¥ **Resultados de tu evaluaci√≥n del sue√±o**

üìå Calidad estimada de tu sue√±o: **{clase}**

üí° **Recomendaciones personalizadas:**
- {rec[0]}
- {rec[1]}
- {rec[2]}

üìò **Reporte Ejecutivo Personalizado**
{reporte}

Si deseas otra evaluaci√≥n, puedes indicarlo cuando quieras ü§ç
"""

        audio = generar_audio(txt_final)

        st.session_state.messages.append({
            "role": "assistant",
            "content": txt_final,
            "audio": audio,
        })

        # RESET DEL FLUJO
        st.session_state["procesando_resultado"] = False
        st.session_state["modo_analisis"] = False
        st.session_state["indice_pregunta"] = 0
        st.session_state["inputs_usuario"] = {}

        st.rerun()
        return

    # =====================================================================
    # COMANDOS ESPECIALES
    # =====================================================================
    comando = detectar_comando_especial(user_text or "")
    if comando == "cancelar":
        st.session_state["modo_analisis"] = False
        st.session_state["indice_pregunta"] = 0
        st.session_state["inputs_usuario"] = {}
        st.session_state.messages.append({
            "role": "assistant",
            "content": "He cancelado la evaluaci√≥n del sue√±o. Podemos seguir platicando de forma libre üòä."
        })
        return

    elif comando == "reiniciar":
        st.session_state["modo_analisis"] = True
        st.session_state["indice_pregunta"] = 0
        st.session_state["inputs_usuario"] = {}
        _, txt = PREGUNTAS[0]
        st.session_state.messages.append({
            "role": "assistant",
            "content": "Reiniciamos la evaluaci√≥n desde el inicio.\n\n" + txt
        })
        return

    # =====================================================================
    # PARCHE ANTI-INDEXERROR
    # =====================================================================
    idx = st.session_state.get("indice_pregunta", 0)

    if not isinstance(idx, int) or idx < 0 or idx >= len(PREGUNTAS):
        st.session_state["modo_analisis"] = True
        st.session_state["indice_pregunta"] = 0
        st.session_state["inputs_usuario"] = {}
        st.session_state.messages.append({
            "role": "assistant",
            "content": (
                "Hubo un peque√±o desajuste en el orden de las preguntas üòÖ.\n"
                "Vamos a reiniciar la evaluaci√≥n desde el inicio.\n\n"
                f"{PREGUNTAS[0][1]}"
            )
        })
        return

    # =====================================================================
    # VALIDACI√ìN DE RESPUESTA NUM√âRICA
    # =====================================================================
    key, _ = PREGUNTAS[idx]
    valor, error_msg = validar_respuesta_numerica(user_text, key)

    if error_msg:
        st.session_state.messages.append({"role": "assistant", "content": error_msg})
        st.rerun()
        return

    # =====================================================================
    # GUARDAR RESPUESTA
    # =====================================================================
    st.session_state["inputs_usuario"][key] = valor
    st.session_state["indice_pregunta"] += 1

    # =====================================================================
    # ¬øA√öN HAY PREGUNTAS?
    # =====================================================================
    if st.session_state["indice_pregunta"] < len(PREGUNTAS):
        _, siguiente_txt = PREGUNTAS[st.session_state["indice_pregunta"]]
        st.session_state.messages.append({
            "role": "assistant",
            "content": siguiente_txt
        })
        st.rerun()
        return

    # =====================================================================
    # üèÅ FIN DEL FLUJO ‚Üí ACTIVAR PREDICCI√ìN ANN
    # =====================================================================
    st.session_state["procesando_resultado"] = True

    st.session_state.messages.append({
        "role": "assistant",
        "content": "‚è≥ Procesando tu informaci√≥n... dame unos segundos üò¥üåô"
    })

    st.rerun()

    # Reset del flujo
    st.session_state["modo_analisis"] = False
    st.session_state["indice_pregunta"] = 0
    st.session_state["inputs_usuario"] = {}

# ============================================
# üöÄ Procesamiento autom√°tico tras el mensaje de carga
# ============================================

if st.session_state.get("procesando_resultado", False):
    manejar_respuesta_analisis("")   # ejecuta siguiente paso sin requerir prompt


if user_prompt:
    # Mostrar mensaje del usuario
    st.session_state.messages.append({"role": "user", "content": user_prompt})
    st.chat_message("user").write(user_display or user_prompt)

    # Si estamos en modo an√°lisis ‚Üí usamos flujo ANN robusto
    if st.session_state["modo_analisis"]:
        manejar_respuesta_analisis(user_prompt)
    else:
        # Conversaci√≥n libre con el modelo de lenguaje
        conversation = [{"role": "system", "content": stronger_prompt_sueno}]
        conversation.extend(
            {"role": m["role"], "content": m["content"]}
            for m in st.session_state.messages
        )

        with st.chat_message("assistant"):
            with st.spinner("Analizando tus patrones de sue√±o... üò¥"):
                stream = client_openai.chat.completions.create(
                    model=MODEL_CHAT,
                    messages=conversation,
                    stream=True
                )
                respuesta = st.write_stream(stream)

        # Guardar respuesta como texto
        nuevo_msg = {"role": "assistant", "content": respuesta}

        # Generar audio de la respuesta (como en el dise√±o original)
        audio_bytes = generar_audio(respuesta)
        if audio_bytes:
            nuevo_msg["audio"] = audio_bytes

        st.session_state.messages.append(nuevo_msg)
